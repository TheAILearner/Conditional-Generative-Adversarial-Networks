{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional Generative Adversarial Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand intution behind this model follow this blog:\n",
    "\n",
    "1. [Conditional Generative Adversarial Networks (CGAN): Introduction and Implementation](https://theailearner.com/2019/09/27/conditional-generative-adversarial-networks-cgan-introduction-and-implementation/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generative adversarial networks (GANs) are trained to generate new images that look similar to original images. Let say we have trained a GAN network on MNIST digit dataset that consists of 0-9 handwritten digits. Now if we generate images from this trained GAN network, it will randomly generate images which can be any digit between 0 to 9. But if we want to generate images only for a particular digit, it will be difficult. One way is to find a mapping between random noise given as input to generator and images generated by the network. But with the variations in random input noise, it is really difficult to find the mapping. Here comes the conditional GANs.\n",
    "\n",
    "A GAN network will be a conditional GAN if we train both the discriminator and generator conditioned on some sort of auxiliary information. This information can be class labels, black&white images, and other modalities. In this blog, we will learn how to generate images from a conditional GANs (cGAN) conditioned on the class label.\\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Initialize Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Reshape, BatchNormalization, LeakyReLU, Conv2DTranspose, Conv2D, AveragePooling2D, Flatten, Embedding, Concatenate\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.datasets import mnist\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#ignore warnings in the output\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "batch_size = 16\n",
    "half_batch_size = 8\n",
    "latent_dim = 100\n",
    "iterations = 50000\n",
    "optimizer = Adam(0.0002, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator in Conditional GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In generator we are taking two inputs, one is random noise of shape (100,) and another is class label of shape (1,) which will be an integer between 0-9. This extra input taken as class label will be our condition to GAN. During test time we will use this class label as a condition to generate images for that specific class only.\n",
    "\n",
    "Here we have also added Embedding layer to this conditional input which consists of weights and will be trained during the generator training. This embedding layer converts positive integers to a dense vector of fixed size. Here we have taken embedding of size 50. After this embedding layer we have added a dense layer and then reshaped it to make compatible during concatenation with random noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator():\n",
    "\n",
    "    input_gen = Input(shape = (1, ))\n",
    "    embed_gen = Embedding(10, 50)(input_gen)\n",
    "    dense_layer_gen = Dense(7*7)(embed_gen)\n",
    "    reshaped_dense_gen = Reshape((7, 7, 1))(dense_layer_gen)\n",
    "\n",
    "    input_gen_2 = Input(shape = (latent_dim,))\n",
    "    dense1 = Reshape((7,7,16))(Dense(7*7*16)(input_gen_2))\n",
    "\n",
    "    concat_layer_gen = Concatenate()([reshaped_dense_gen, dense1])\n",
    "    batch_norm_1 = BatchNormalization()(concat_layer_gen)\n",
    "    trans_1 = Conv2DTranspose(128, 3, padding='same', activation=LeakyReLU(alpha=0.2), strides=(2, 2))(batch_norm_1)\n",
    "    batch_norm_2 = BatchNormalization()(trans_1)\n",
    "    trans_2 = Conv2DTranspose(128, 3, padding='same', activation=LeakyReLU(alpha=0.2), strides=(2, 2))(batch_norm_2)\n",
    "    output = Conv2D(1, (28,28), activation='tanh', padding='same')(trans_2)\n",
    "    gen_model = Model([input_gen, input_gen_2], output)\n",
    "    gen_model.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    print(gen_model.summary())\n",
    "\n",
    "    return gen_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_15 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 1, 50)        500         input_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_16 (InputLayer)           (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 1, 49)        2499        embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 784)          79184       input_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_9 (Reshape)             (None, 7, 7, 1)      0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_10 (Reshape)            (None, 7, 7, 16)     0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 7, 7, 17)     0           reshape_9[0][0]                  \n",
      "                                                                 reshape_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 7, 7, 17)     68          concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTrans (None, 14, 14, 128)  19712       batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 14, 14, 128)  512         conv2d_transpose_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTrans (None, 28, 28, 128)  147584      batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 28, 28, 1)    100353      conv2d_transpose_8[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 350,412\n",
      "Trainable params: 350,122\n",
      "Non-trainable params: 290\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "generator_model = generator() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator in Conditional GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In discriminator also we are taking two inputs one is image of shape (28, 28, 1) and another is class label of shape (1,) which will be an integer between 0-9. Discriminator is consists of convolution, batch norm and pooling layer. Output from discriminator will discriminate beteen real (images from training data) and fake images (images generated by generator network). Also embedding layer is used to achieve similar purpose as it was used in generator network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator():\n",
    "\n",
    "    input_class = Input(shape = (1, ))\n",
    "    embed = Embedding(10, 50)(input_class)\n",
    "    dense_layer = Dense(28*28)(embed)\n",
    "    reshaped_dense = Reshape((28,28,1))(dense_layer)\n",
    "\n",
    "    input_disc = Input(shape = (28, 28, 1))\n",
    "\n",
    "    concat_layer = Concatenate()([input_disc, reshaped_dense])\n",
    "    conv_1 = Conv2D(16, 3, padding = 'same', activation = LeakyReLU(alpha=0.2))(concat_layer)\n",
    "    batch_norm1 = BatchNormalization()(conv_1)\n",
    "    pool_1 = AveragePooling2D(strides = (2,2))(batch_norm1)\n",
    "    conv_2 = Conv2D(32, 3, padding = 'same', activation = LeakyReLU(alpha=0.2))(pool_1)\n",
    "    batch_norm2 = BatchNormalization()(conv_2)\n",
    "    pool_2 = AveragePooling2D(strides = (2,2))(batch_norm2)\n",
    "    conv_3 = Conv2D(64, 3, padding = 'same', activation = LeakyReLU(alpha=0.2))(pool_2)\n",
    "    batch_norm3 = BatchNormalization()(conv_3)\n",
    "    pool_3 = AveragePooling2D(strides = (2,2))(conv_3)\n",
    "    flatten_1 = Flatten()(pool_3)\n",
    "    output = Dense(1, activation = 'sigmoid')(flatten_1)\n",
    "    disc_model = Model([input_class, input_disc], output)\n",
    "    disc_model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    print(disc_model.summary())\n",
    "\n",
    "    return disc_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_17 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, 1, 50)        500         input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 1, 784)       39984       embedding_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_18 (InputLayer)           (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_11 (Reshape)            (None, 28, 28, 1)    0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 28, 28, 2)    0           input_18[0][0]                   \n",
      "                                                                 reshape_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 28, 28, 16)   304         concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 28, 28, 16)   64          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 14, 14, 16)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 14, 14, 32)   4640        average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 14, 14, 32)   128         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 7, 7, 32)     0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 7, 7, 64)     18496       average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 3, 3, 64)     0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 576)          0           average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 1)            577         flatten_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 64,693\n",
      "Trainable params: 64,597\n",
      "Non-trainable params: 96\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "discriminator_model = discriminator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined Model in Conditional GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created a combined model which takes two inputs one is random noise of shape (100, ) and another is the class label of shape (1, ). Generator model takes these two inputs and generates the new image which is then fed to the discriminator model to predict the output. Here, only the generator is being trained and the discriminator is made non-trainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined():\n",
    "\n",
    "    inputs = Input(shape = (latent_dim,)) \n",
    "    input_comb = Input(shape = (1,))\n",
    "    gen_img = generator_model([input_comb, inputs])\n",
    "    discriminator_model.trainable = False\n",
    "    outs = discriminator_model([input_comb, gen_img])\n",
    "    comb_model = Model([input_comb, inputs], outs)\n",
    "    comb_model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    print(comb_model.summary())\n",
    "\n",
    "    return comb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_20 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_19 (InputLayer)           (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_8 (Model)                 (None, 28, 28, 1)    350412      input_20[0][0]                   \n",
      "                                                                 input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_9 (Model)                 (None, 1)            64693       input_20[0][0]                   \n",
      "                                                                 model_8[1][0]                    \n",
      "==================================================================================================\n",
      "Total params: 415,105\n",
      "Trainable params: 350,122\n",
      "Non-trainable params: 64,983\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "combined_model = combined()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training this model will consist of the following steps:\n",
    "\n",
    "1. Normalize all the training images from the MNIST dataset.\n",
    "2. Train the discriminator model with labeled (used for conditioning discriminator) real images (take a batch from dataset).\n",
    "3. Sample noise of vector size 100 and train the discriminator model with fake images generated by generator network and random labels (condition to discriminator) as input to discriminator.\n",
    "5. Sample noise of vector size 100 and sample random labels (condition to generator) then train the combined model to train the generator network.\n",
    "6. Repeat steps from 2-5 for some number of iterations. I have trained it for 50000 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "\n",
    "    train_data = (x_train.astype(np.float32) - 127.5) / 127.5\n",
    "    train_data = np.expand_dims(train_data, -1)\n",
    "    train_data_y = y_train\n",
    "\n",
    "    for i in range(iterations):\n",
    "\n",
    "        batch_indx = np.random.randint(0, train_data.shape[0], size = (half_batch_size))\n",
    "        batch_x = train_data[batch_indx]\n",
    "        batch_y = train_data_y[batch_indx]\n",
    "\n",
    "        real_loss = discriminator_model.train_on_batch([batch_y, batch_x], np.ones((half_batch_size,1)))\n",
    "\n",
    "        random_y = np.random.randint(0,10,half_batch_size)\n",
    "        input_noise = np.random.normal(0, 1, size=(half_batch_size, 100))\n",
    "        gen_outs = generator_model.predict([random_y, input_noise])\n",
    "\n",
    "        fake_loss = discriminator_model.train_on_batch([random_y, gen_outs], np.zeros((half_batch_size,1)))\n",
    "\n",
    "        full_batch_input_noise = np.random.normal(0, 1, size=(batch_size, 100))\n",
    "        gan_loss = combined_model.train_on_batch([np.random.randint(0,10,batch_size), full_batch_input_noise], np.array([1] * batch_size))\n",
    "        \n",
    "        if i%5000 == 0:\n",
    "            print(i, fake_loss, real_loss, gan_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0.2801106, 0.875] [0.08982224, 1.0] [2.6066833, 0.0]\n",
      "5000 [0.30531767, 1.0] [0.34472957, 0.875] [1.3662237, 0.0]\n",
      "10000 [0.42256582, 1.0] [0.7189435, 0.375] [1.024968, 0.0625]\n",
      "15000 [0.48499775, 1.0] [0.7175186, 0.5] [0.7707323, 0.375]\n",
      "20000 [0.60733163, 0.75] [0.8087877, 0.375] [0.9900814, 0.0625]\n",
      "25000 [0.5294056, 0.75] [0.55973434, 0.625] [0.7530277, 0.375]\n",
      "30000 [0.7308177, 0.0] [0.76910543, 0.375] [0.9317108, 0.0]\n",
      "35000 [0.7628757, 0.25] [0.60768694, 0.625] [0.8073195, 0.1875]\n",
      "40000 [0.6196747, 0.875] [1.0113817, 0.25] [0.82207954, 0.25]\n",
      "45000 [0.5384978, 0.625] [0.4449643, 1.0] [0.8200073, 0.3125]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 25 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# training the network\n",
    "\n",
    "# generating new images from trained network\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "r, c = 5, 5\n",
    "noise = np.random.normal(0, 1, (10, 100))\n",
    "\n",
    "gen_imgs = []\n",
    "\n",
    "for indx in range(5):\n",
    "    gen_imgs.extend(generator_model.predict([np.array([indx]*5), noise]))\n",
    "    \n",
    "# Rescale images 0 - 1\n",
    "gen_imgs = np.array(gen_imgs)\n",
    "gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "fig, axs = plt.subplots(r, c)\n",
    "cnt = 0\n",
    "for i in range(r):\n",
    "    for j in range(c):\n",
    "        axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "        axs[i,j].axis('off')\n",
    "        cnt += 1\n",
    "        \n",
    "plt.show()\n",
    "fig.savefig(\"mnist.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
